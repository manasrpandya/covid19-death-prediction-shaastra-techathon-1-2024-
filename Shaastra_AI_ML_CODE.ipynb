{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7MeNqEHtczE"
      },
      "source": [
        "#Modules and Data upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EqrIscRRtRm1"
      },
      "outputs": [],
      "source": [
        "#importing necessary modules\n",
        "!pip install keras-tuner\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM, Reshape, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from kerastuner.tuners import BayesianOptimization\n",
        "#uploading data\n",
        "train_data = pd.read_csv('train_data_covid.csv')\n",
        "test_data = pd.read_csv('test_data_covid.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08bvgC3ktlCz"
      },
      "source": [
        "#Feature Engg."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nplc6MgLr6ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "#converting 'Date' to datetime to sort data\n",
        "train_data['Date'] = pd.to_datetime(train_data['Date'])\n",
        "test_data['Date'] = pd.to_datetime(test_data['Date'])\n",
        "train_data.sort_values(by=['State/UnionTerritory', 'Date'], inplace=True)\n",
        "test_data.sort_values(by=['State/UnionTerritory', 'Date'], inplace=True)\n",
        "\n",
        "#Feature engineering - adding high-correlation features\n",
        "\n",
        "train_data['Confirmed_lag_12'] = train_data.groupby('State/UnionTerritory')['Confirmed'].shift(12).fillna(method='bfill')\n",
        "train_data['Cured_lag_12'] = train_data.groupby('State/UnionTerritory')['Cured'].shift(12).fillna(method='bfill')\n",
        "\n",
        "test_data['Confirmed_lag_12'] = test_data.groupby('State/UnionTerritory')['Confirmed'].shift(12).fillna(method='bfill')\n",
        "test_data['Cured_lag_12'] = test_data.groupby('State/UnionTerritory')['Cured'].shift(12).fillna(method='bfill')\n",
        "\n",
        "#adding rolling means and standard deviations for confirmed and cured cases\n",
        "train_data['Confirmed_Rolling_Mean'] = train_data.groupby('State/UnionTerritory')['Confirmed'].transform(lambda x: x.rolling(window=7, min_periods=1).mean()).fillna(method='bfill')\n",
        "train_data['Cured_Rolling_Mean'] = train_data.groupby('State/UnionTerritory')['Cured'].transform(lambda x: x.rolling(window=7, min_periods=1).mean()).fillna(method='bfill')\n",
        "train_data['Confirmed_Rolling_Std'] = train_data.groupby('State/UnionTerritory')['Confirmed'].transform(lambda x: x.rolling(window=7, min_periods=1).std()).fillna(method='bfill')\n",
        "train_data['Cured_Rolling_Std'] = train_data.groupby('State/UnionTerritory')['Cured'].transform(lambda x: x.rolling(window=7, min_periods=1).std()).fillna(method='bfill')\n",
        "\n",
        "test_data['Confirmed_Rolling_Mean'] = test_data.groupby('State/UnionTerritory')['Confirmed'].transform(lambda x: x.rolling(window=7, min_periods=1).mean()).fillna(method='bfill')\n",
        "test_data['Cured_Rolling_Mean'] = test_data.groupby('State/UnionTerritory')['Cured'].transform(lambda x: x.rolling(window=7, min_periods=1).mean()).fillna(method='bfill')\n",
        "test_data['Confirmed_Rolling_Std'] = test_data.groupby('State/UnionTerritory')['Confirmed'].transform(lambda x: x.rolling(window=7, min_periods=1).std()).fillna(method='bfill')\n",
        "test_data['Cured_Rolling_Std'] = test_data.groupby('State/UnionTerritory')['Cured'].transform(lambda x: x.rolling(window=7, min_periods=1).std()).fillna(method='bfill')\n",
        "\n",
        "#applying exponentially weighted moving averages (EWMA)\n",
        "train_data['Confirmed_EWMA'] = train_data.groupby('State/UnionTerritory')['Confirmed'].transform(lambda x: x.ewm(span=7, min_periods=1).mean()).fillna(method='bfill')\n",
        "train_data['Cured_EWMA'] = train_data.groupby('State/UnionTerritory')['Cured'].transform(lambda x: x.ewm(span=7, min_periods=1).mean()).fillna(method='bfill')\n",
        "\n",
        "test_data['Confirmed_EWMA'] = test_data.groupby('State/UnionTerritory')['Confirmed'].transform(lambda x: x.ewm(span=7, min_periods=1).mean()).fillna(method='bfill')\n",
        "test_data['Cured_EWMA'] = test_data.groupby('State/UnionTerritory')['Cured'].transform(lambda x: x.ewm(span=7, min_periods=1).mean()).fillna(method='bfill')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1x7TX-gtnoa"
      },
      "source": [
        "#Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RV0VtdAPtbtr"
      },
      "outputs": [],
      "source": [
        "#selecting the features and target\n",
        "features = [\n",
        "    'Confirmed_lag_12', 'Cured_lag_12', 'State/UnionTerritory',\n",
        "    'Confirmed_Rolling_Mean', 'Cured_Rolling_Mean', 'Confirmed_Rolling_Std', 'Cured_Rolling_Std',\n",
        "    'Confirmed_EWMA', 'Cured_EWMA'\n",
        "]\n",
        "target = 'Deaths'\n",
        "\n",
        "#Defining the preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), [\n",
        "            'Confirmed_lag_12', 'Cured_lag_12', 'Confirmed_Rolling_Mean', 'Cured_Rolling_Mean', 'Confirmed_Rolling_Std', 'Cured_Rolling_Std',\n",
        "    'Confirmed_EWMA', 'Cured_EWMA'\n",
        "        ]),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['State/UnionTerritory'])\n",
        "    ])\n",
        "\n",
        "#applying preprocessing to the data\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "X_test = test_data[features]\n",
        "\n",
        "X = preprocessor.fit_transform(X)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "#spliting the data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARpe48x0wAmq"
      },
      "source": [
        "#Sample valued Model\\( for quick evaluation \\)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZaZk3n31ukZS"
      },
      "outputs": [],
      "source": [
        "\"\"\" CODE FOR A SAMPLE\n",
        "sample hyp par values for faste evaulation \"\"\"\n",
        "#defining the sequence-to-sequence model with LSTM layers\n",
        "def build_seq2seq_model(input_shape, output_sequence_length):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),\n",
        "        Reshape((1, input_shape)),\n",
        "        LSTM(64, activation='relu', return_sequences=False),  #encoder LSTM with 64 units\n",
        "        RepeatVector(output_sequence_length),  #repeat the output sequence length times\n",
        "        LSTM(64, activation='relu', return_sequences=True),  #decoder LSTM with 64 units\n",
        "        TimeDistributed(Dense(1))  #output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "#training the sequence-to-sequence model on 80% of the data to find RMSE\n",
        "seq2seq_model = build_seq2seq_model(X_train.shape[1], 1)\n",
        "seq2seq_model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_val, y_val),\n",
        "                  callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "\n",
        "#predicting on the validation set using sequence-to-sequence model\n",
        "val_predictions_seq2seq = seq2seq_model.predict(X_val)\n",
        "val_predictions_seq2seq = val_predictions_seq2seq.flatten()\n",
        "\n",
        "#calculating RMSE for sequence-to-sequence model\n",
        "val_rmse_seq2seq = np.sqrt(mean_squared_error(y_val, val_predictions_seq2seq))\n",
        "print(f\"Validation RMSE (Sequence-to-Sequence): {val_rmse_seq2seq}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#sample submissions file"
      ],
      "metadata": {
        "id": "tCnRjXVEISbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training the final model on the full dataset\n",
        "final_model = build_seq2seq_model(X.shape[1], 1)\n",
        "final_model.fit(X, y, epochs=70, batch_size=32, verbose=1)\n",
        "\n",
        "predictions= final_model.predict(X_test)\n",
        "predictions= predictions.flatten()\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'Sno': test_data['Sno'],\n",
        "    'Deaths': np.round(predictions).astype(int)\n",
        "})\n",
        "submission.to_csv('submission_sample_seq2seq.csv', index=False)\n",
        "print(\"submission file saved successfully.\")"
      ],
      "metadata": {
        "id": "cmryU3GbISog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8f3LD0xtuqi"
      },
      "source": [
        "#Model to find the actual best hyperparamter values \\(bayesian optimization \\)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clnaXCIvt4oC"
      },
      "outputs": [],
      "source": [
        "\"\"\" ACTUAL CODE USED FOR SUBMISSION FILE \"\"\"\n",
        "\n",
        "#defining the model\n",
        "def build_tuned_seq2seq_model(hp):\n",
        "    input_shape = X_train.shape[1]\n",
        "    output_sequence_length = 1\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),\n",
        "        Reshape((1, input_shape)),\n",
        "        LSTM(hp.Int('units', min_value=64, max_value=256, step=64),\n",
        "             activation='relu', return_sequences=False),  #encoder LSTM\n",
        "        RepeatVector(output_sequence_length),  #repeat the output sequence length times\n",
        "        LSTM(hp.Int('units', min_value=64, max_value=256, step=64),\n",
        "             activation='relu', return_sequences=True),  #decoder LSTM\n",
        "        TimeDistributed(Dense(1))  #output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "                  loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "#tuning the model using bayesian optimisation\n",
        "\n",
        "tuner = BayesianOptimization(\n",
        "    build_tuned_seq2seq_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=50, #use lower number of trials for faster, BUT LESS ACCURATE convergence\n",
        "    executions_per_trial=2,\n",
        "    directory='my_dir',\n",
        "    project_name='seq2seq'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=70, batch_size=32, validation_data=(X_val, y_val),\n",
        "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "#saving the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "#predicting and calculate RMSE\n",
        "val_predictions_seq2seq = best_model.predict(X_val)\n",
        "val_predictions_seq2seq = val_predictions_seq2seq.flatten()\n",
        "val_rmse_seq2seq = np.sqrt(mean_squared_error(y_val, val_predictions_seq2seq))\n",
        "print(f\"Validation RMSE (Sequence-to-Sequence with Tuning): {val_rmse_seq2seq}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siYQkMcXuIlZ"
      },
      "source": [
        "# original submissions file creation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the final model on the full dataset\n",
        "final_model = tuner.get_best_models(num_models=1)[0]\n",
        "final_model.fit(X, y, epochs=70, batch_size=32, verbose=1)\n",
        "\n",
        "predictions= final_model.predict(X_test)\n",
        "predictions= predictions.flatten()\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'Sno': test_data['Sno'],\n",
        "    'Deaths': np.round(predictions).astype(int)\n",
        "})\n",
        "submission.to_csv('submission_seq2seq.csv', index=False)\n",
        "print(\"submission file saved successfully.\")\n"
      ],
      "metadata": {
        "id": "BB94J3VeVMr0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}